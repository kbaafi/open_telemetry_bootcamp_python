receivers:
  otlp:
    protocols:
      http:
        endpoint: 0.0.0.0:4318
      grpc:
        endpoint: 0.0.0.0:4320
processors:
  batch:
    timeout: 1s  # Increase value for production
  resource:
    attributes:
    - key: test.key
      value: "gateway"
      action: insert
  tail_sampling:
    decision_wait: 2s
    num_traces: 100
    expected_new_traces_per_sec: 1
    policies:
      [
        {
          name: errors-policy,
          type: status_code,
          status_code: { status_codes: [ERROR] },
        },
        {
          name: latency-policy,
          type: latency,
          latency: {threshold_ms: 1500}
        }
      ]
exporters:
  prometheus:
    endpoint: "0.0.0.0:8889"
    send_timestamps: true
    namespace: otel_prom
    const_labels:
      prom_label_1: prom_value_1
  otlp:
    endpoint: "jaeger:4317"
    tls:
      insecure: true
  debug:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 200
  
extensions:
  health_check:
  pprof:
    endpoint: :1888
  zpages:
    endpoint: :55679
service:
  # extensions: [pprof, zpages, health_check]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [tail_sampling, batch, resource]
      exporters: [otlp]
    metrics:
      receivers: [otlp]
      processors: [batch, resource]
      exporters: [prometheus]
